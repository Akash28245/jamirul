# -*- coding: utf-8 -*-
"""Vegetable Identification from picture using maching learing12.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QlfSzrOcLXECvv1wemESC85h7Bt4kQIM
"""

!pip install keras-metrics

from __future__ import absolute_import, division, print_function, unicode_literals

import tensorflow as tf
print("Num GPUs Available: ", len(tf.config.experimental.list_physical_devices('GPU')))

import os
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import tensorflow as tf
from keras.applications.inception_v3 import InceptionV3
from keras.preprocessing import image
from keras.models import Model
from keras.layers import Dense, GlobalAveragePooling2D
import matplotlib.pyplot as plt
import keras_metrics as km

from google.colab import drive
drive.mount('/content/drive')

import os

# Path to your train directory
train_base_path = '/content/drive/MyDrive/Vegetable/Train'  # Replace 'your_directory_path' with the path to your main directory

image_extensions = ['.jpg', '.png', '.jpeg']  # Add or remove image extensions as needed

print("Number of images in each training folder:")
for folder in os.listdir(train_base_path):
    folder_path = os.path.join(train_base_path, folder)
    if os.path.isdir(folder_path):
        image_count = sum(1 for file in os.listdir(folder_path) if os.path.splitext(file)[1].lower() in image_extensions)
        print(f"{folder}: {image_count} images")

# Path to your test directory
test_base_path = '/content/drive/MyDrive/Vegetable/Test'  # Replace 'your_directory_path' with the path to your main directory

print("\nNumber of images in each testing folder:")
for folder in os.listdir(test_base_path):
    folder_path = os.path.join(test_base_path, folder)
    if os.path.isdir(folder_path):
        image_count = sum(1 for file in os.listdir(folder_path) if os.path.splitext(file)[1].lower() in image_extensions)
        print(f"{folder}: {image_count} images")

test_directory = '/content/drive/MyDrive/Vegetable/Test'
testset = [os.path.join(test_directory, folder) for folder in os.listdir(test_directory) if os.path.isdir(os.path.join(test_directory, folder))]

# Get sizes of each class in the test set
sizes_testset = [len(os.listdir(path)) if os.path.exists(path) else 0 for path in testset]

import os
import numpy as np
from keras.preprocessing.image import ImageDataGenerator

# Image Data Generators
train_datagen = ImageDataGenerator(rescale = 1./255,
                                   rotation_range=40,
                                   width_shift_range =0.2,
                                   height_shift_range=0.2,
                                   shear_range = 0.2,
                                   zoom_range = 0.2,
                                   horizontal_flip = True)

validation_datagen = ImageDataGenerator(rescale = 1./255)
test_datagen = ImageDataGenerator(rescale = 1./255)

# Constants
BATCH_SIZE = 25
IMG_HEIGHT = 150
IMG_WIDTH = 150

# Calculate total number of training images
train_directory = '/content/drive/MyDrive/Vegetable/Train'
total_train_images = sum([len(os.listdir(os.path.join(train_directory, folder))) for folder in os.listdir(train_directory) if os.path.isdir(os.path.join(train_directory, folder))])

STEPS_PER_EPOCH = np.ceil(total_train_images/BATCH_SIZE)

# Data Generators
training_set = train_datagen.flow_from_directory(directory=train_directory,
                                                 target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                 batch_size=BATCH_SIZE,
                                                 class_mode='categorical')

test_set = test_datagen.flow_from_directory(directory='/content/drive/MyDrive/Vegetable/Test',
                                            target_size=(IMG_HEIGHT, IMG_WIDTH),
                                            batch_size=BATCH_SIZE,
                                            class_mode='categorical')

validation_set = validation_datagen.flow_from_directory(directory='/content/drive/MyDrive/Vegetable/Test',
                                                        target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                        batch_size=BATCH_SIZE,
                                                        class_mode='categorical')

pip install pyheif

import matplotlib.pyplot as plt
import numpy as np

def show_batch(image_batch, label_batch, class_names):
    batch_size = len(image_batch)
    side = int(np.ceil(np.sqrt(batch_size)))  # Calculate the side length for the grid of images
    plt.figure(figsize=(20,20))
    for i in range(batch_size):
        plt.subplot(side, side, i+1)
        plt.imshow(image_batch[i])
        label_index = np.argmax(label_batch[i])  # Find the index of the '1' in the one-hot encoded label
        plt.title(class_names[label_index])
        plt.axis('off')

# Get class names from the test_set generator
class_names = list(test_set.class_indices.keys())

# Get a batch of images and labels from the test_set generator
image_batch, label_batch = next(test_set)
show_batch(image_batch, label_batch, class_names)

import matplotlib.pyplot as plt

# Data
vegetables = ['Tomato', 'Spinach', 'Potato', 'Peas', 'Eggplant', 'Cucumber', 'Beetroot', 'Cauliflower', 'Cabbage', 'Corn', 'Carrot', 'Capsicum']
total_data = [102, 107, 87, 110, 94, 104, 98, 89, 102, 97, 92, 99]

# Create a pie chart
plt.figure(figsize=(8, 8))
plt.pie(total_data, labels=vegetables, autopct='%1.1f%%', startangle=140)
plt.title('Distribution of Total Data for Vegetables')
plt.show()

from keras.applications.inception_v3 import InceptionV3
from keras.layers import GlobalAveragePooling2D, Dense
from keras.models import Model

# Using InceptionV3 as the base model
base_model = InceptionV3(weights='imagenet', include_top=False)

# If you want to use MobileNetV2, uncomment the following line:
# base_model = keras.applications.mobilenet_v2.MobileNetV2(weights='imagenet', include_top=False)

# Add a global spatial average pooling layer
x = base_model.output
x = GlobalAveragePooling2D()(x)

# Add a fully-connected layer
x = Dense(1024, activation='relu')(x)

# Add a logistic layer(as i have 12 categories)
predictions = Dense(61, activation='softmax')(x)

# Create the final model
model = Model(inputs=base_model.input, outputs=predictions)

from keras.applications.inception_v3 import InceptionV3
from keras.layers import GlobalAveragePooling2D, Dense
from keras.models import Model
from tensorflow.keras.optimizers import RMSprop
import tensorflow as tf

# Using InceptionV3 as the base model
base_model = InceptionV3(weights='imagenet', include_top=False)

# Add a global spatial average pooling layer
x = base_model.output
x = GlobalAveragePooling2D()(x)

# Add a fully-connected layer
x = Dense(1024, activation='relu')(x)

# Assuming you have 12 classes, change this number if you have a different number of classes
predictions = Dense(12, activation='softmax')(x)

# Create the final model
model = Model(inputs=base_model.input, outputs=predictions)

# Setting layers as trainable or non-trainable
for layer in model.layers[:249]:
    layer.trainable = False
for layer in model.layers[249:]:
    layer.trainable = True

# Recompile the model with the updated trainable layers
model.compile(optimizer=RMSprop(learning_rate=0.0001),
              loss='categorical_crossentropy',
              metrics=[tf.keras.metrics.Precision(name='precision'),
                       tf.keras.metrics.Recall(name='recall'),
                       'accuracy'])

# Early stopping callback
early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=7)

# Fit the model (assuming training_set and validation_set are already defined)
history2 = model.fit(
    training_set,
    steps_per_epoch=STEPS_PER_EPOCH,
    epochs=30,
    validation_data=validation_set,
    callbacks=[early_stopping]
)

print("Evaluate on test data")
test_loss, test_precision, test_recall,  test_accuracy  = model.evaluate(validation_set, verbose=0)
print("Test Loss: {0:.2f}, Test Precision: {1:.2f}, Test Recall: {2:.2f}, Test Accuracy: {3:.2f}%".format(test_loss,test_precision,test_recall, test_accuracy*100))



"""*For  visualize the training and validation accuracy and loss figure*"""

!pip install matplotlib

import matplotlib.pyplot as plt

# Plot training & validation accuracy values
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(history2.history['accuracy'])
plt.plot(history2.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')

# Plot training & validation loss values
plt.subplot(1, 2, 2)
plt.plot(history2.history['loss'])
plt.plot(history2.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')

plt.show()

# from keras.applications.inception_v3 import InceptionV3
# from keras.layers import Input
# import visualkeras

# # Specify the input shape (adjust it based on your actual input shape)
# input_shape = (224, 224, 3)

# # Create an Input layer with the specified shape
# input_layer = Input(shape=input_shape)

# # Create an instance of InceptionV3 with the specified input layer
# model = InceptionV3(input_tensor=input_layer)

# # Visualize the model
# visualkeras.layered_view(model, legend=True)

"""# **MobileNet**"""

from keras.applications.mobilenet import MobileNet
from keras.layers import GlobalAveragePooling2D, Dense
from keras.models import Model
from tensorflow.keras.optimizers import RMSprop
import tensorflow as tf

# Using MobileNet as the base model
base_model = MobileNet(weights='imagenet', include_top=False)

# Add a global spatial average pooling layer
x = base_model.output
x = GlobalAveragePooling2D()(x)

# Add a fully-connected layer
x = Dense(1024, activation='relu')(x)

# Assuming you have 12 classes, change this number if you have a different number of classes
predictions = Dense(12, activation='softmax')(x)  # Adjusted to 12 classes

# Create the final model
model = Model(inputs=base_model.input, outputs=predictions)

# Setting layers as trainable or non-trainable
for layer in model.layers[:-20]:
    layer.trainable = False
for layer in model.layers[-20:]:
    layer.trainable = True

# Recompile the model with the updated trainable layers
model.compile(optimizer=RMSprop(learning_rate=0.0001),
              loss='categorical_crossentropy',
              metrics=[tf.keras.metrics.Precision(name='precision'),
                       tf.keras.metrics.Recall(name='recall'),
                       'accuracy'])

# Early stopping callback
early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=7)

# Assuming training_set and validation_set are already defined
history2 = model.fit(training_set,
                     steps_per_epoch=STEPS_PER_EPOCH,
                     epochs=30,
                     validation_data=validation_set,
                     callbacks=[early_stopping])

print("Evaluate on test data")
test_loss, test_precision, test_recall,  test_accuracy  = model.evaluate(validation_set, verbose=0)
print("Test Loss: {0:.2f}, Test Precision: {1:.2f}, Test Recall: {2:.2f}, Test Accuracy: {3:.2f}%".format(test_loss,test_precision,test_recall, test_accuracy*100))

"""*For visualize the training and validation accuracy and loss figure*"""

!pip install -q matplotlib

import matplotlib.pyplot as plt

# Plot training & validation accuracy values
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(history2.history['accuracy'])
plt.plot(history2.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')

# Plot training & validation loss values
plt.subplot(1, 2, 2)
plt.plot(history2.history['loss'])
plt.plot(history2.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')

plt.show()

# from keras.applications.mobilenet import MobileNet
# from keras.layers import Input
# import visualkeras

# # Specify the input shape (adjust it based on your actual input shape)
# input_shape = (224, 224, 3)

# # Create an Input layer with the specified shape
# input_layer = Input(shape=input_shape)

# # Create an instance of MobileNet with the specified input layer
# model = MobileNet(input_tensor=input_layer)

# # Visualize the model
# visualkeras.layered_view(model, legend=True)

import cv2
import numpy as np
import os

# Define the path to the external image you want to analyze
image_path = '/content/drive/MyDrive/Vegetable/Train/beetroot/Image_1.jpg'  # Replace with the path to your external image

# Load the external image
external_image = cv2.imread(image_path)

# Check if the image was loaded correctly
if external_image is None:
    print("Error: Unable to load image at path:", image_path)
    exit()  # Exit if the image cannot be loaded

# Resize the external image to a consistent size (e.g., 150x150)
external_image = cv2.resize(external_image, (150, 150))

# Define the path to your dataset directory
dataset_directory = '/content/drive/MyDrive/Vegetable/Train'  # Replace with the path to your training dataset directory

# Initialize variables to store the best match and its corresponding folder name
best_match_score = float('inf')
best_match_folder = None

# Iterate through the folders in your dataset
for folder in os.listdir(dataset_directory):
    folder_path = os.path.join(dataset_directory, folder)

    # Iterate through the images in each folder
    for filename in os.listdir(folder_path):
        image_file_path = os.path.join(folder_path, filename)

        # Load the dataset image
        dataset_image = cv2.imread(image_file_path)

        # Check if the dataset image was loaded correctly
        if dataset_image is None:
            continue  # Skip this image if it cannot be loaded

        # Resize the dataset image to the same size as the external image
        dataset_image = cv2.resize(dataset_image, (150, 150))

        # Calculate the absolute difference between the external image and dataset image
        diff = cv2.absdiff(external_image, dataset_image)

        # Calculate the sum of absolute differences as a matching score
        match_score = np.sum(diff)

        # Check if this is the best match so far
        if match_score < best_match_score:
            best_match_score = match_score
            best_match_folder = folder

# Print the folder name that best matches the external image
if best_match_folder is not None:
    print("It's", best_match_folder)
else:
    print("No matching folder found.")